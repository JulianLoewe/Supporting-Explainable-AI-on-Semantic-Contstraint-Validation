This chapter introduced the main concepts used in this thesis. The first part featured the concepts necessary for semantic constraint validation. First, knowledge graphs are introduced in the context of RDF graphs, which give entities in the graph a semantic context. Next, building on N-Triples, Turtle is presented as a serialization format for RDF graphs. As it turns out, SPARQL, the W3C recommended query language to query data from RDF graphs, uses a syntax similar to Turtle with the addition of query variables; extending RDF triples to triple patterns. Evaluating a triple pattern over a knowledge graph gives a set of SPARQL solution mappings. Using algebraic operations over these sets, manifested in the SPARQL language as graph patterns, allows for writing expressive SPARQL queries. In this work, the SPARQL evaluation of the query $Q \in \mathbf{Q}$ over the knowledge graph $G \in \mathbf{G}$ is denoted with $[[Q]]_G$. Among other use cases, in the abstract syntax for the SHACL core constraint components as introduced by Cormen et al. \cite{corman2018semantics}, SPARQL queries are used to define the target of SHACL shapes. Multiple interconnected SHACL shapes $S$ form a shape schema $\mathcal{S} = (S,\uri{TARG}, \uri{DEF})$, which represent constraints over a knowledge graph. The SHACL validation of $\mathcal{S}$ over a knowledge graph $G$ is performed by a SHACL engine and gives the validation results in the form of the entity validation function. 

In the second part, explainable AI is introduced as the extension of AI, allowing one to comprehend and trust an AI agent's results. A focus is on explainable machine learning and the main concepts of machine learning: An inducer solves a given task $(\mathbb{I}, \mathbb{T}, ot)$ by training a machine learning model on a given dataset sampled from $ot$. Whether the resulting model matches the user's expectations (e.g., generalizes well) is usually checked by measuring the model's performance with a performance measure (e.g., mean squared error, accuracy) on a test set sampled separately from the objective truth. Finally, tree-based models and, specifically, decision trees are introduced. A decision tree visualization is discussed, which explains a decision tree trained on the task of approximating the sigmoid function based on the data used to train the model. 